{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.core.serialization\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.hub\n",
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch.mps\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import F1Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5926 659\n"
     ]
    }
   ],
   "source": [
    "def scan_train_images(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    real_data_dir = data_dir / 'pravilniye(correct)'\n",
    "    fake_data_dir = data_dir / 'fictivniye(fictitious)'\n",
    "\n",
    "    real_images = real_data_dir.rglob('*.jpeg')\n",
    "    fake_images = fake_data_dir.rglob('*.jpeg')\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for img in real_images:\n",
    "        data.append((img.as_posix(), 0))\n",
    "\n",
    "    for img in fake_images:\n",
    "        data.append((img.as_posix(), 1))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def scan_test_images(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "\n",
    "    images = data_dir.rglob('*.jpeg')\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for img in images:\n",
    "        data.append((img.as_posix(), 0))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_images = scan_train_images(\n",
    "    'data/case3-datasaur-photo/techosmotr/techosmotr/train/')\n",
    "\n",
    "with open('data/case3-datasaur-photo/test.csv') as fp:\n",
    "    fp.readline()\n",
    "    test_images = [('data/case3-datasaur-photo/techosmotr/techosmotr/test/' +\n",
    "                   line.strip() + '.jpeg', 0) for line in fp]\n",
    "\n",
    "train_images, val_images = train_test_split(train_images, test_size=0.1)\n",
    "\n",
    "print(len(train_images), len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechosmotrDataset(Dataset):\n",
    "    def __init__(self, images, transform=None, target_transform=None):\n",
    "\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_path, label = self.images[index]\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            if isinstance(self.transform,\n",
    "                          albumentations.core.serialization.Serializable):\n",
    "                img = self.transform(image=img)['image']\n",
    "            else:\n",
    "                img = self.transform(img)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.HorizontalFlip(),\n",
    "    A.Affine(scale=[.9, 1.1], translate_percent=.2, rotate=[-180, 180], shear=0, p=1),\n",
    "    # A.RandomSizedCrop([int(IMAGE_SIZE * 0.6), int(IMAGE_SIZE)], IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "target_transform = partial(torch.as_tensor, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TechosmotrDataset(\n",
    "    train_images,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "val_ds = TechosmotrDataset(\n",
    "    val_images,\n",
    "    transform=val_test_transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "test_ds = TechosmotrDataset(\n",
    "    test_images,\n",
    "    transform=val_test_transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "c1 = sum([label for _, label in train_images])\n",
    "c0 = len(train_images) - c1\n",
    "\n",
    "train_weights = [(c0+c1)/c0 if label == 0 else (c0+c1)/c0 for _, label in train_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    BATCH_SIZE,\n",
    "    sampler=WeightedRandomSampler(train_weights, num_samples=max(c0, c1)*2),\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_ds, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_ds, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/contactone/.cache/torch/hub/pytorch_vision_main\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ML/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    with tqdm.tqdm(total=len(dataloader)) as pbar:\n",
    "        for batch, (X, y) in tqdm.tqdm(enumerate(dataloader)):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y = nn.functional.one_hot(y, 2).to(torch.float)\n",
    "\n",
    "            # Compute prediction error\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X)#.logits\n",
    "            try:\n",
    "                loss = loss_fn(pred, y)\n",
    "            except Exception as e:\n",
    "                print(X)\n",
    "                print(y)\n",
    "                print(X.shape)\n",
    "                print(y.shape)\n",
    "                print(e)\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update()\n",
    "            pbar.set_description(f'Epoch {epoch}\\tLoss: {total_loss / len(dataloader):.7f}')\n",
    "    \n",
    "    return {'train_loss': total_loss}\n",
    "\n",
    "\n",
    "\n",
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            pred = logits.argmax(1)\n",
    "            test_loss += loss_fn(logits, nn.functional.one_hot(y, 2).to(torch.float)).item()\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            \n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Accuracy: {(100*correct):>0.1f}%\\tTest loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return {\n",
    "        'val_loss': test_loss,\n",
    "        'val_acc': correct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:22<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('artifacts/oscar_epoch_20.pth')\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "result = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X, y) in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
    "        X = X.to(device)\n",
    "        logits = model(X)\n",
    "        pred = logits.argmax(1).tolist()\n",
    "        result.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76395310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78235074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74477562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70540972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73988993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>73412262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>74208388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>77369587</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>77880820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>79868374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_index  class\n",
       "0     76395310      0\n",
       "1     78235074      0\n",
       "2     74477562      0\n",
       "3     70540972      0\n",
       "4     73988993      0\n",
       "..         ...    ...\n",
       "772   73412262      1\n",
       "773   74208388      1\n",
       "774   77369587      1\n",
       "775   77880820      1\n",
       "776   79868374      1\n",
       "\n",
       "[777 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_images, columns=['file_index', 'class'])\n",
    "df['class'] = result\n",
    "df['file_index'] = df['file_index'].apply(lambda x: x.split('/')[-1])\n",
    "df['file_index'] = df['file_index'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "df.to_csv('output.csv',index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/contactone/Desktop/datasaur/case3/notebook.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/contactone/Desktop/datasaur/case3/notebook.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m models \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/contactone/Desktop/datasaur/case3/notebook.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39martifacts/oscar_epoch_23.pth\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/contactone/Desktop/datasaur/case3/notebook.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39martifacts/charlie_epoch_20.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/contactone/Desktop/datasaur/case3/notebook.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/contactone/Desktop/datasaur/case3/notebook.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m weights \u001b[39m=\u001b[39m [\u001b[39m1.5\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/contactone/Desktop/datasaur/case3/notebook.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m models \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    torch.load('artifacts/oscar_epoch_23.pth'),\n",
    "    torch.load('artifacts/charlie_epoch_20.pth')\n",
    "]\n",
    "\n",
    "weights = [1.5, 1]\n",
    "\n",
    "models = [model.to(device) for model in models]\n",
    "\n",
    "for model in models:\n",
    "    model.eval()\n",
    "\n",
    "result = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X, y) in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
    "        X = X.to(device)\n",
    "        logits = [model(X) for model in models]\n",
    "\n",
    "        prob = [nn.functional.softmax(logit, dim=1) * w / sum(weights) for logit, w in zip(logits, weights)]\n",
    "        \n",
    "        prob = sum(prob)\n",
    "\n",
    "        pred = prob.argmax(1).tolist()\n",
    "        result.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76395310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78235074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74477562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70540972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73988993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>73412262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>74208388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>77369587</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>77880820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>79868374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_index  class\n",
       "0     76395310      0\n",
       "1     78235074      0\n",
       "2     74477562      0\n",
       "3     70540972      0\n",
       "4     73988993      0\n",
       "..         ...    ...\n",
       "772   73412262      1\n",
       "773   74208388      1\n",
       "774   77369587      1\n",
       "775   77880820      1\n",
       "776   79868374      1\n",
       "\n",
       "[777 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_images, columns=['file_index', 'class'])\n",
    "df['class'] = result\n",
    "df['file_index'] = df['file_index'].apply(lambda x: x.split('/')[-1])\n",
    "df['file_index'] = df['file_index'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "df.to_csv('data/results.csv',index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasaur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
